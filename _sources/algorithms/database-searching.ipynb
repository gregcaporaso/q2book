{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence homology searching \n",
    "\n",
    "In this chapter we'll talk about using pairwise alignment to search databases of biological sequences with the goal of identifying sequence homology. We previously defined homology between a pair of sequences to mean that those sequences are derived from a common ancestral sequence. Homology searching is an essential part of making inferences about where a biological sequence came from, and/or what it does. In most cases, if you have an unannotated biological sequence, such as the following protein sequence, it's very hard (really, impossible) to know what it is without more information.\n",
    "\n",
    "What a researcher will often do is search this sequence, their **query**, against some **reference database** of annotated sequences to learn what function the sequence performs (if the reference database contains functional annotation of sequences) and/or what organisms are likely to encode this sequence in their genome (if the reference database contains taxonomic annotation of sequences).\n",
    "\n",
    "````{admonition} Interactive exercise\n",
    "Whose genome is the following sequence encoded in? What is its function? Take a minute now to answer these questions using the [Protein BLAST homology search tool on the NCBI website](https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastp&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome).\n",
    "\n",
    "```\n",
    ">mystery-sequence1\n",
    "MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFS\n",
    "NVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIV\n",
    "NNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLE\n",
    "GKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQT\n",
    "LLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETK\n",
    "CTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISN\n",
    "CVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIAD\n",
    "YNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPC\n",
    "NGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVN\n",
    "FNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITP\n",
    "GTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSY\n",
    "ECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTI\n",
    "SVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQE\n",
    "VFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDC\n",
    "LGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAM\n",
    "QMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALN\n",
    "TLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRA\n",
    "SANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPA\n",
    "ICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDP\n",
    "LQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDL\n",
    "QELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDD\n",
    "SEPVLKGVKLHYT\n",
    "```\n",
    "\n",
    "````\n",
    "\n",
    "In the context of database searching, a query sequence and a reference sequence that we hypothesize to be homologous can be identical to one another, or they can differ as a result of mutation events. When sequences differ, we're often then interested in how much they differ, or their pairwise similarity, which can help us identify the most closely related of several homologs in the reference database. There is an important distinction in the terms **homology** and **similarity**: homology is a discrete variable, and similarity is a continuous variable. A pair of biological sequences either *are* or *are not* derived from a common ancestor, but they can be more or less similar to each other. Saying that two sequences are 80% homologous doesn't make sense. What people generally mean when they say this is that two sequences are 80% similar, and as a result they are hypothesizing homology between the sequences.\n",
    "\n",
    "**Similarity** between a pair of sequences can be computed in a few different ways. In this text, unless otherwise noted, we'll compute similar as: $Similarity = 1 - Hamming\\ distance$. Recall that Hamming distance is the fraction of positions that differ between aligned sequences. Similarity is therefore the inverse of that: the fraction of positions that do not differ between aligned sequences.\n",
    "\n",
    "## Defining the problem \n",
    "\n",
    "As mentioned above, if we want to perform a homology search we'll have one or more **query sequences**, and for each we want to know which sequence(s) in a reference database it is most similar to.\n",
    "\n",
    "Sequence homology searching can be implemented in a few ways. In this chapter, we'll use the local alignment function that we worked with in the Pairwise Alignment chapter, ``local_pairwise_align_ssw``, run it many times to search one query sequence against many reference sequences, and investigate the highest scoring alignment(s) to identify the best database match. Remember that you can always get help with a function by passing it as an argument to ``help``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function local_pairwise_align_ssw in module skbio.alignment._pairwise:\n",
      "\n",
      "local_pairwise_align_ssw(sequence1, sequence2, **kwargs)\n",
      "    Align query and target sequences with Striped Smith-Waterman.\n",
      "    \n",
      "    State: Experimental as of 0.4.0.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    sequence1 : DNA, RNA, or Protein\n",
      "        The first unaligned sequence\n",
      "    sequence2 : DNA, RNA, or Protein\n",
      "        The second unaligned sequence\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    tuple\n",
      "        ``TabularMSA`` object containing the aligned sequences, alignment score\n",
      "        (float), and start/end positions of each input sequence (iterable\n",
      "        of two-item tuples). Note that start/end positions are indexes into the\n",
      "        unaligned sequences.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This is a wrapper for the SSW package [1]_.\n",
      "    \n",
      "    For a complete list of optional keyword-arguments that can be provided,\n",
      "    see ``skbio.alignment.StripedSmithWaterman``.\n",
      "    \n",
      "    The following kwargs will not have any effect: `suppress_sequences`,\n",
      "    `zero_index`, and `protein`\n",
      "    \n",
      "    If an alignment does not meet a provided filter, `None` will be returned.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Zhao, Mengyao, Wan-Ping Lee, Erik P. Garrison, & Gabor T.\n",
      "       Marth. \"SSW Library: An SIMD Smith-Waterman C/C++ Library for\n",
      "       Applications\". PLOS ONE (2013). Web. 11 July 2014.\n",
      "       http://www.plosone.org/article/info:doi/10.1371/journal.pone.0082138\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    skbio.alignment.StripedSmithWaterman\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skbio.alignment import local_pairwise_align_ssw\n",
    "help(local_pairwise_align_ssw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When our reference database starts getting hundreds of millions of bases long (as would be the case if we were searching against 97% OTUs from the [Greengenes small-subunit ribosomal RNA (SSU rRNA) reference database](http://www.ncbi.nlm.nih.gov/pubmed/22134646)), billions of bases long (as would be the case if we were searching against [the human genome](https://genome.ucsc.edu/cgi-bin/hgGateway)) or trillions of bases long (as would be the case if we were searching against the [NCBI non-redundant nucleotide database](http://www.ncbi.nlm.nih.gov/refseq/)), runtime becomes an important consideration. For that reason, learning about *heuristic algorithms* is an essential part of learning about sequence homology searching. Heuristic algorithms apply some rules (i.e., heuristics) to approximate the correct solution to a problem in a fraction of the runtime that would be required if we wanted to be guaranteed to find the correct solution. Heuristic algorithms are very common in bioinformatics, and we'll use them in several other places in this book.\n",
    "\n",
    "While we'll be aligning nucleotide sequences in this chapter, the same concepts apply to protein homology searching.\n",
    "\n",
    "## Loading annotated sequences \n",
    "\n",
    "````{margin}\n",
    "```{note}\n",
    "We're accessing Greengenes sequences here through the [QIIME default reference project](https://github.com/biocore/qiime-default-reference). The QIIME default reference project isn't actually used by recent versions of QIIME but it's a convenient resource for accessing a collection of 16S sequences from Python. This resource is handy if you need some sequences for experimental purposes, but is outdated and shouldn't be used in practice.\n",
    "```\n",
    "````\n",
    "\n",
    "The first thing we'll do as we learn about sequence homology searching is load some annotated sequences. The sequences that we're going to work with are derived from the [Greengenes](http://greengenes.secondgenome.com/) database. Greengenes is a database of 16S rRNA gene sequences, a component of the archaeal and bacterial [ribosome](http://www.nature.com/scitable/definition/ribosome-194) (the molecular machine that drives translation of mRNA to proteins). This gene is of a lot of interest to biologists because it's one of about 200 genes that are encoded in the genomes of all known cellular organisms. The sequences in Greengenes are taxonomically annotated, meaning that we'll have a collection of gene sequences and the taxonomic identity of the organism whose genome the sequence is found in. If we search an unannotated 16S rRNA query sequence against this database, we can make inferences about what organism our query sequence is from.\n",
    "\n",
    "First, let's load Greengenes into a list of ``skbio.DNA`` sequence objects, and associate the taxonomy of each sequence as sequence metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# This cell performs some configuration for this notebook. It's hidden by\n",
    "# default because it's not relevant to the content of this chapter. You'll\n",
    "# occasionally notice that I hide this type of information so it's not \n",
    "# distracting.\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "from IPython.core import page\n",
    "page.page = print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import qiime_default_reference as qdr\n",
    "import skbio\n",
    "\n",
    "def load_taxonomy_reference_database(verbose=True):\n",
    "    # Load the taxonomic data\n",
    "    reference_taxonomy = {}\n",
    "    for e in open(qdr.get_reference_taxonomy()):\n",
    "        seq_id, seq_tax = e.strip().split('\\t')\n",
    "        reference_taxonomy[seq_id] = seq_tax\n",
    "\n",
    "    # Load the reference sequences, and associate the taxonomic annotation with\n",
    "    # each as metadata\n",
    "    reference_db = []\n",
    "    for e in skbio.io.read(qdr.get_reference_sequences(), format='fasta', constructor=skbio.DNA):\n",
    "        if e.has_degenerates():\n",
    "            # For the purpose of this lesson, we're going to ignore sequences that contain\n",
    "            # degenerate characters (i.e., characters other than A, C, G, or T)\n",
    "            continue\n",
    "        seq_tax = reference_taxonomy[e.metadata['id']]\n",
    "        e.metadata['taxonomy'] = seq_tax\n",
    "        reference_db.append(e)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"%s sequences were loaded from the reference database.\" % len(reference_db))\n",
    "\n",
    "    return reference_taxonomy, reference_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88452 sequences were loaded from the reference database.\n"
     ]
    }
   ],
   "source": [
    "reference_taxonomy, reference_db = load_taxonomy_reference_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll just inspect a couple of the sequences we loaded. Notice how the specificity of our taxonomic annotations (i.e., how many taxonomic levels are annotated and unknown) differs for different sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "-----------------------------------------------------------------------\n",
       "Metadata:\n",
       "    'description': ''\n",
       "    'id': '1111883'\n",
       "    'taxonomy': 'k__Bacteria; p__Gemmatimonadetes; c__Gemm-1; o__; f__;\n",
       "                 g__; s__'\n",
       "Stats:\n",
       "    length: 1428\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 61.90%\n",
       "-----------------------------------------------------------------------\n",
       "0    GCTGGCGGCG TGCCTAACAC ATGTAAGTCG AACGGGACTG GGGGCAACTC CAGTTCAGTG\n",
       "60   GCAGACGGGT GCGTAACACG TGAGCAACTT GTCCGACGGC GGGGGATAGC CGGCCCAACG\n",
       "...\n",
       "1320 GCCGCGGTGA ATACGTTCCC GGGCCTTGTA CACACCGCCC GTCACGCCAT GGAAGCCGGA\n",
       "1380 GGGACCCGAA ACCGGTGGGC CAACCGCAAG GGGGCAGCCG TCTAAGGT"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_db[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "----------------------------------------------------------------------\n",
       "Metadata:\n",
       "    'description': ''\n",
       "    'id': '4483258'\n",
       "    'taxonomy': 'k__Archaea; p__Crenarchaeota; c__Thermoprotei;\n",
       "                 o__Thermoproteales; f__Thermoproteaceae; g__; s__'\n",
       "Stats:\n",
       "    length: 2123\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 58.36%\n",
       "----------------------------------------------------------------------\n",
       "0    CTGGTTGATC CTGCCGGACC CGACCGCTAT CGGGGTGGGG CTTAGCCATG CGAGTCAAGC\n",
       "60   GCCCCAGGGA CCCGCTGGGG TGCGGCGCAC GGCTCAGTAA CACGTGGCCA ACCTACCCTC\n",
       "...\n",
       "2040 ATAATCTCCT TATTGTCTGA TCCTTATGCA TTTTCCTTTG GCCCATCCCG TGAATACGCG\n",
       "2100 CGGTGAATAC GTCCCTGCCC CTT"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_db[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of runtime, we're going to work through this chapter using a random sample of sequences from this database. Here we'll use Python's [random module](https://docs.python.org/3/library/random.html) to select sequences at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 sequences are present in the subsampled database.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "reference_db = random.sample(reference_db, k=5000)\n",
    "print(\"%s sequences are present in the subsampled database.\" % len(reference_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also extract some sequences from Greengenes to use as query sequences in our database searches. This time we won't annotate them (to simulate not knowing what organisms they're from). We'll also trim these sequences so they're shorter than the full length references. This will simulate obtaining a partial gene sequence, as is most common with the current sequencing technologies (as of this writing), but will also help to make the examples run faster.\n",
    "\n",
    "Note that some of our query sequences may also be in our subsampled reference database and some won't. This is realistic: sometimes we're working with sequences that are exact matches to known sequences, and sometimes we're working with sequences that don't match any known sequences (or at least any in the reference database that we're working with)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def load_taxonomy_query_sequences(start_position=100, length=200):\n",
    "    queries = []\n",
    "    for e in skbio.io.read(qdr.get_reference_sequences(), format='fasta', constructor=skbio.DNA):\n",
    "        if e.has_degenerates():\n",
    "            # For the purpose of this lesson, we're going to ignore sequences that contain\n",
    "            # degenerate characters (i.e., characters other than A, C, G, or T)\n",
    "            continue\n",
    "        e = e[start_position:start_position + length]\n",
    "        queries.append(e)\n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_taxonomy_query_sequences()\n",
    "queries = random.sample(queries, k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect a couple of the query sequences that we'll work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "---------------------------------------------------------------------\n",
       "Metadata:\n",
       "    'description': ''\n",
       "    'id': '195759'\n",
       "Stats:\n",
       "    length: 200\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 53.50%\n",
       "---------------------------------------------------------------------\n",
       "0   ACTGAGCGGC GGACGGGTGA GTAACGCGTG GGTAACCTGC CTCATACAGG GGGATAACAG\n",
       "60  TTAGAAATGA CTGCTAATAC CGCATAAGAC CACAGCACCG CATGGTGCGG GGGTAAAAAC\n",
       "120 TCCGGTGGTA TGAGATGGAC CCGCGTCTGA TTAGCTAGTT GGTAAGGTAA CGGCTTACCA\n",
       "180 AGGCGACAAT CCATAGCCGA"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "---------------------------------------------------------------------\n",
       "Metadata:\n",
       "    'description': ''\n",
       "    'id': '50499'\n",
       "Stats:\n",
       "    length: 200\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 55.00%\n",
       "---------------------------------------------------------------------\n",
       "0   ACACAGTGGG ATCTTAGTGG CGGACGGGTG AGTAACGCGT GGGTAACCTG CCGTATACAG\n",
       "60  GGGGATAACA CCTGGAAACA GGTGCTAATA CCGCATAAGC GCACGATGTC GCATGACAAC\n",
       "120 GTGTGAAAAG CCGAGACGGT ATACGATGGA CCCGCGTCTG ATTAGCTGGT TGGTGAGGTA\n",
       "180 GAGGCTCACC AAGGCGACGA"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the problem \n",
    "\n",
    "The problem that we are going to address here is as follows. We now have a query sequence ($q_i$) which is not taxonomically annotated (meaning we don't know the taxonomy of the organism whose genome it is found in), and a reference database ($R$) of taxonomically annotated sequences ($r_1, r_2, r_3, ... r_n$). We want to infer a taxonomic annotation for $q_i$. We'll do this by identifying the most similar sequence(s) in $R$ and associating their taxonomy with $q_i$. Because we actually do know the taxonomy of $q_i$ (to the extent that we trust the annotations in $R$), we can evaluate how well this approach works.\n",
    "\n",
    "There are a few realistic features of the situation that we've set up here that I want you to be aware of.\n",
    "\n",
    "1. All of the query and reference sequences are homologous. In this case, they are all sequences of the 16S rRNA gene from archaea and bacteria. This may or may not be the case in real-world applications. Sometimes you'll work with gene-specific databases such as Greengenes, and sometimes you'll work with non-specific databases such as the NCBI nucleotide database (nr). Regardless, the search process is similar.\n",
    "2. The distance between each query sequence and its most closely related sequences in $R$ will vary widely. Sometimes $q$ will be an exact match to a reference sequence $r_i$, and sometimes we may have as little as $50\\%$ similarity.\n",
    "\n",
    "As we work through the next sections, imagine that we're exploring scaling this system up, so that instead of searching just one or a few query sequences against the reference database, we ultimately want to apply this to search millions of sequences against the database. This would be the real-world problem we faced if we had collected 16S rRNA sequences from the environment (which would of course be unannotated) using high-throughput DNA sequencing.\n",
    "\n",
    "## A complete homology search function \n",
    "\n",
    "Let's define a homology search function that aligns each provided query sequences $q_i$ with each of our reference database sequences ($r_1, r_2, r_3, ... r_n$). This function will take as input one or more query sequences, and the reference database. We'll call the top scoring alignments for each $q_i$ the *best hits*, and we'll specifically request some number (`n`) of best hits for each $q_i$. The output of this function will be a summary of the `n` best hits for each query sequence, including some technical information about the alignment and the taxonomy associated with the corresponding reference sequence. We'll then review the taxonomy annotations for our best hits, and from those make an inference about the taxonomy annotation for $q_i$.\n",
    "\n",
    "Spend a minute looking at this function and try to understand what it's doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skbio.alignment import local_pairwise_align_ssw\n",
    "\n",
    "def local_alignment_search(queries, reference_db, n=5,\n",
    "                           aligner=local_pairwise_align_ssw):\n",
    "    results = []\n",
    "    indices = []\n",
    "    for q in queries:\n",
    "        # first we'll compute all of the alignments and their associated scores\n",
    "        hits = []\n",
    "        for r in reference_db:\n",
    "            aln, score, _ = aligner(q, r)\n",
    "            hits.append([r.metadata['id'], score, aln,\n",
    "                         r.metadata['taxonomy']])\n",
    "        # then we reverse-sort them by score, and return the n highest\n",
    "        # scoring alignments (this needs to be updated so we only\n",
    "        # ever keep track of the n highest scoring alignments)\n",
    "        best_hits = sorted(hits, key=lambda e: e[1], reverse=True)[:n]\n",
    "        if len(best_hits) == 0:\n",
    "            # if there are no hits, log that information\n",
    "            indices.append((q.metadata['id'], \"no matches\"))\n",
    "            results.append((\"n/a\", np.nan, np.nan, np.nan))\n",
    "        else:\n",
    "            # otherwise compile and track some information about the n\n",
    "            # best hits\n",
    "            for r_id, score, aln, r_tax in best_hits:\n",
    "                percent_similarity = (100 * (1. - aln[0].distance(aln[1])))\n",
    "                aln_length = aln.shape[1]\n",
    "                indices.append((q.metadata['id'], r_id))\n",
    "                results.append((r_tax, percent_similarity,\n",
    "                                aln_length, score))\n",
    "    index = pd.MultiIndex.from_tuples(indices, names=['query', 'reference'])\n",
    "    columns = ['reference taxonomy', 'percent similarity',\n",
    "               'alignment length', 'score']\n",
    "    results = pd.DataFrame(results, index=index, columns=columns)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform some database searches. You can run the remaining code cells in this section a few times to experiment with searching different query sequences against the same reference database.\n",
    "\n",
    "This next cell, which is the one that actually performs the database searches, will take a little bit of time to run (maybe up to a minute or two). There is some code in this cell that will track the runtime. As it's running, think about how many query sequences we're searching against how many reference sequences, and refer back to the number of sequences in the full reference database. Does this strategy seem scalable to millions of sequences, which as mentioned above might be our ultimate goal? When you know the per-sequence runtime of this search, estimate how long it would take to do this in seconds for one million sequences. Convert the time in seconds to a unit that will be more meaningful to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 3.9740 sec per query\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>reference taxonomy</th>\n",
       "      <th>percent similarity</th>\n",
       "      <th>alignment length</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <th>reference</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">523768</th>\n",
       "      <th>180083</th>\n",
       "      <td>k__Bacteria; p__Firmicutes; c__Clostridia; o__...</td>\n",
       "      <td>98.492462</td>\n",
       "      <td>199</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195556</th>\n",
       "      <td>k__Bacteria; p__Firmicutes; c__Clostridia; o__...</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>200</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186328</th>\n",
       "      <td>k__Bacteria; p__Firmicutes; c__Clostridia; o__...</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>200</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174493</th>\n",
       "      <td>k__Bacteria; p__Firmicutes; c__Clostridia; o__...</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>200</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165926</th>\n",
       "      <td>k__Bacteria; p__Firmicutes; c__Clostridia; o__...</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>200</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">106027</th>\n",
       "      <th>2670730</th>\n",
       "      <td>k__Bacteria; p__Proteobacteria; c__Gammaproteo...</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>200</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094881</th>\n",
       "      <td>k__Bacteria; p__Proteobacteria; c__Gammaproteo...</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>200</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4328035</th>\n",
       "      <td>k__Bacteria; p__Proteobacteria; c__Gammaproteo...</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>198</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373263</th>\n",
       "      <td>k__Bacteria; p__Proteobacteria; c__Gammaproteo...</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>200</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613575</th>\n",
       "      <td>k__Bacteria; p__Proteobacteria; c__Gammaproteo...</td>\n",
       "      <td>95.959596</td>\n",
       "      <td>198</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">811846</th>\n",
       "      <th>546187</th>\n",
       "      <td>k__Bacteria; p__Proteobacteria; c__Alphaproteo...</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>200</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143849</th>\n",
       "      <td>k__Bacteria; p__Proteobacteria; c__Alphaproteo...</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>200</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621042</th>\n",
       "      <td>k__Bacteria; p__Proteobacteria; c__Alphaproteo...</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>200</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435412</th>\n",
       "      <td>k__Bacteria; p__Proteobacteria; c__Alphaproteo...</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>200</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789831</th>\n",
       "      <td>k__Bacteria; p__Proteobacteria; c__Alphaproteo...</td>\n",
       "      <td>92.537313</td>\n",
       "      <td>201</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">516648</th>\n",
       "      <th>4306178</th>\n",
       "      <td>k__Bacteria; p__Actinobacteria; c__Actinobacte...</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>200</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092725</th>\n",
       "      <td>k__Bacteria; p__Actinobacteria; c__Actinobacte...</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>200</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375127</th>\n",
       "      <td>k__Bacteria; p__Actinobacteria; c__Actinobacte...</td>\n",
       "      <td>91.707317</td>\n",
       "      <td>205</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200634</th>\n",
       "      <td>k__Bacteria; p__Actinobacteria; c__Actinobacte...</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>200</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530833</th>\n",
       "      <td>k__Bacteria; p__Actinobacteria; c__Actinobacte...</td>\n",
       "      <td>90.099010</td>\n",
       "      <td>202</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reference taxonomy  \\\n",
       "query  reference                                                      \n",
       "523768 180083     k__Bacteria; p__Firmicutes; c__Clostridia; o__...   \n",
       "       195556     k__Bacteria; p__Firmicutes; c__Clostridia; o__...   \n",
       "       186328     k__Bacteria; p__Firmicutes; c__Clostridia; o__...   \n",
       "       174493     k__Bacteria; p__Firmicutes; c__Clostridia; o__...   \n",
       "       165926     k__Bacteria; p__Firmicutes; c__Clostridia; o__...   \n",
       "106027 2670730    k__Bacteria; p__Proteobacteria; c__Gammaproteo...   \n",
       "       3094881    k__Bacteria; p__Proteobacteria; c__Gammaproteo...   \n",
       "       4328035    k__Bacteria; p__Proteobacteria; c__Gammaproteo...   \n",
       "       2373263    k__Bacteria; p__Proteobacteria; c__Gammaproteo...   \n",
       "       613575     k__Bacteria; p__Proteobacteria; c__Gammaproteo...   \n",
       "811846 546187     k__Bacteria; p__Proteobacteria; c__Alphaproteo...   \n",
       "       1143849    k__Bacteria; p__Proteobacteria; c__Alphaproteo...   \n",
       "       621042     k__Bacteria; p__Proteobacteria; c__Alphaproteo...   \n",
       "       3435412    k__Bacteria; p__Proteobacteria; c__Alphaproteo...   \n",
       "       789831     k__Bacteria; p__Proteobacteria; c__Alphaproteo...   \n",
       "516648 4306178    k__Bacteria; p__Actinobacteria; c__Actinobacte...   \n",
       "       1092725    k__Bacteria; p__Actinobacteria; c__Actinobacte...   \n",
       "       4375127    k__Bacteria; p__Actinobacteria; c__Actinobacte...   \n",
       "       200634     k__Bacteria; p__Actinobacteria; c__Actinobacte...   \n",
       "       530833     k__Bacteria; p__Actinobacteria; c__Actinobacte...   \n",
       "\n",
       "                  percent similarity  alignment length  score  \n",
       "query  reference                                               \n",
       "523768 180083              98.492462               199    383  \n",
       "       195556              97.500000               200    375  \n",
       "       186328              97.000000               200    370  \n",
       "       174493              96.500000               200    365  \n",
       "       165926              96.000000               200    360  \n",
       "106027 2670730             99.000000               200    388  \n",
       "       3094881             98.500000               200    385  \n",
       "       4328035             96.969697               198    366  \n",
       "       2373263             96.500000               200    365  \n",
       "       613575              95.959596               198    356  \n",
       "811846 546187              96.500000               200    365  \n",
       "       1143849             93.500000               200    335  \n",
       "       621042              93.000000               200    330  \n",
       "       3435412             92.500000               200    325  \n",
       "       789831              92.537313               201    323  \n",
       "516648 4306178             96.500000               200    365  \n",
       "       1092725             96.000000               200    360  \n",
       "       4375127             91.707317               205    315  \n",
       "       200634              91.000000               200    306  \n",
       "       530833              90.099010               202    296  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "current_queries = random.sample(queries, k=4)\n",
    "results = local_alignment_search(current_queries, reference_db)\n",
    "stop_time = time.time()\n",
    "print(\"Runtime: %1.4f sec per query\" % ((stop_time - start_time) / len(current_queries)))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to answer our initial question: what is the most likely taxonomic annotation for each of our query sequences? Spend a few minutes reviewing this information, and write down what you think the most likely taxonomic annotation is for each of the query sequences. Here are some hints to help you out:\n",
    "\n",
    " * The ``k``, ``p``, ``c``, ``o``, ``f``, ``g``, and ``s`` refer to *kingdom*, *phylum*, *class*, *order*, *family*, *genus*, and *species*, respectively. If you see an annotation for a reference sequence that looks like ``g__``, that means that the genus is unknown for that sequence.\n",
    " * Just as the reference taxonomy annotations don't always go down to the species level, your taxonomic annotations don't have to either. Not assigning at a given level implies that you're uncertain about what the annotation should be at that level, and it's usually better just to indicate that you're uncertain rather than make a bad guess. If you're uncertain of what the species is, assign the query ``s__`` and try to decide what the most likely genus is. If you're uncertain of the genus, assign ``g__``, and try to decide what the most likely family is...\n",
    " * As you look at each of the reference taxonomy annotations below, refer back to the table above to look at the percent similarity between each query and reference, and maybe the length of the alignments and their scores. These values give you an idea of how confident you should be in each of your taxonomic annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest taxonomies for query 523768 (in order):\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Lachnospiraceae; g__[Ruminococcus]; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Ruminococcaceae; g__; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Ruminococcaceae; g__Faecalibacterium; s__prausnitzii\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Ruminococcaceae; g__; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Ruminococcaceae; g__Faecalibacterium; s__prausnitzii\n",
      "\n",
      "Closest taxonomies for query 106027 (in order):\n",
      "  k__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Vibrionales; f__Vibrionaceae; g__Vibrio; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Vibrionales; f__Vibrionaceae; g__Vibrio; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Vibrionales; f__Vibrionaceae; g__Vibrio; s__atlanticus\n",
      "  k__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Vibrionales; f__Pseudoalteromonadaceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Vibrionales; f__Vibrionaceae; g__Vibrio; s__\n",
      "\n",
      "Closest taxonomies for query 811846 (in order):\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodobacterales; f__Rhodobacteraceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodobacterales; f__Rhodobacteraceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodobacterales; f__Rhodobacteraceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodobacterales; f__Rhodobacteraceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodobacterales; f__Rhodobacteraceae; g__; s__\n",
      "\n",
      "Closest taxonomies for query 516648 (in order):\n",
      "  k__Bacteria; p__Actinobacteria; c__Actinobacteria; o__Actinomycetales; f__Micrococcaceae; g__Rothia; s__dentocariosa\n",
      "  k__Bacteria; p__Actinobacteria; c__Actinobacteria; o__Actinomycetales; f__Micrococcaceae; g__Rothia; s__dentocariosa\n",
      "  k__Bacteria; p__Actinobacteria; c__Actinobacteria; o__Actinomycetales; f__Micrococcaceae; g__Rothia; s__aeria\n",
      "  k__Bacteria; p__Actinobacteria; c__Actinobacteria; o__Actinomycetales; f__Micrococcaceae; g__Rothia; s__amarae\n",
      "  k__Bacteria; p__Actinobacteria; c__Actinobacteria; o__Actinomycetales; f__Micrococcaceae; g__Microbispora; s__rosea\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in current_queries:\n",
    "    q_id = q.metadata['id']\n",
    "    print('Closest taxonomies for query %s (in order):' % q_id)\n",
    "    for e in results['reference taxonomy'][q_id]:\n",
    "        print(' ', e)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have taxonomic annotations for all of the Greengenes sequences (though as you probably have noticed by now, they differ in their specificity), we can next look at taxonomy associated with each of our queries in Greengenes. How do your annotations compare to those from Greengenes, which we'll print out in the next cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known taxonomy for query 523768:\n",
      " k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Ruminococcaceae; g__Faecalibacterium; s__prausnitzii\n",
      "\n",
      "Known taxonomy for query 106027:\n",
      " k__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Vibrionales; f__Vibrionaceae; g__Vibrio; s__\n",
      "\n",
      "Known taxonomy for query 811846:\n",
      " k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodobacterales; f__Rhodobacteraceae; g__; s__\n",
      "\n",
      "Known taxonomy for query 516648:\n",
      " k__Bacteria; p__Actinobacteria; c__Actinobacteria; o__Actinomycetales; f__Micrococcaceae; g__Rothia; s__mucilaginosa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in current_queries:\n",
    "    q_id = q.metadata['id']\n",
    "    print('Known taxonomy for query %s:\\n %s' % (q_id, reference_taxonomy[q_id]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing the runtime for database searches \n",
    "\n",
    "In the examples above, it's taking on the order of 5-15 seconds to search a single sequence against our subset of Greengenes. This makes sense when you think about the computations that are being performed. For every sequence in our reference database (5000, if you haven't modified the database subsampling step) it is computing the $F$ and $T$ matrices described in the Pairwise Alignment chapter, and then tracing back the matrix to compute the aligned sequences. Given all of that, the fact that computation only takes 5-15 seconds is pretty incredible. However, that doesn't change the fact that this doesn't scale to real-world applications because we'd have to wait way too long for results. Performing all pairwise alignments is prohibitively expensive for database searching.\n",
    "\n",
    "As we discussed in the previous chapter, the run time of pairwise alignment scales quadratically with sequence length. Database searching, at least in the example we're exploring in this chapter, is a bit of a different problem however. Our sequence lengths aren't changing, but rather it takes a long time because we're performing a computationally expensive step, pairwise alignment, many times. Our database is fixed in that the number of sequences in it doesn't change and the sequences themselves don't change. Our query sequences are all exactly the same length in this example (remember that we set that above, when we sliced a single region from reference database sequences to create our query sequences). Let's explore how the runtime of this database search scales under these constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of query seqs</th>\n",
       "      <th>Number of reference seqs</th>\n",
       "      <th>Median query seq length</th>\n",
       "      <th>Median reference seq length</th>\n",
       "      <th>Runtime (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1434.5</td>\n",
       "      <td>0.085800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1417.5</td>\n",
       "      <td>0.076304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>0.075654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>0.516122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>0.399368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1443.5</td>\n",
       "      <td>0.394945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1426.5</td>\n",
       "      <td>0.776113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>0.791824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>0.787630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1430.5</td>\n",
       "      <td>1.196813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>1.234219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>1.200206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of query seqs  Number of reference seqs  Median query seq length  \\\n",
       "0                    1.0                     100.0                    200.0   \n",
       "1                    1.0                     100.0                    200.0   \n",
       "2                    1.0                     100.0                    200.0   \n",
       "3                    5.0                     100.0                    200.0   \n",
       "4                    5.0                     100.0                    200.0   \n",
       "5                    5.0                     100.0                    200.0   \n",
       "6                   10.0                     100.0                    200.0   \n",
       "7                   10.0                     100.0                    200.0   \n",
       "8                   10.0                     100.0                    200.0   \n",
       "9                   15.0                     100.0                    200.0   \n",
       "10                  15.0                     100.0                    200.0   \n",
       "11                  15.0                     100.0                    200.0   \n",
       "\n",
       "    Median reference seq length  Runtime (s)  \n",
       "0                        1434.5     0.085800  \n",
       "1                        1417.5     0.076304  \n",
       "2                        1419.0     0.075654  \n",
       "3                        1433.0     0.516122  \n",
       "4                        1412.0     0.399368  \n",
       "5                        1443.5     0.394945  \n",
       "6                        1426.5     0.776113  \n",
       "7                        1428.0     0.791824  \n",
       "8                        1429.0     0.787630  \n",
       "9                        1430.5     1.196813  \n",
       "10                       1431.0     1.234219  \n",
       "11                       1440.0     1.200206  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "def tabulate_local_alignment_search_runtime(queries, reference_db, n_query_sequences,\n",
    "                                            n_reference_sequences, search_function):\n",
    "    data = []\n",
    "    # we'll iterate over the pairs of number of query sequences\n",
    "    # and number of reference sequences, and compute the runtime\n",
    "    # of the database search three times for each pair (so we\n",
    "    # have some idea of the variance in the runtimes). this is\n",
    "    # achieved here with a nested for loop (i.e., a for loop\n",
    "    # within a for loop).\n",
    "    for nq, nr in itertools.product(n_query_sequences, n_reference_sequences):\n",
    "        for i in range(3):\n",
    "            # select nq query sequences at random\n",
    "            current_queries = random.sample(queries, k=nq)\n",
    "            # select nr reference sequences at random\n",
    "            temp_reference_db = random.sample(reference_db, k=nr)\n",
    "            # run the search and store its runtime\n",
    "            start_time = time.time()\n",
    "            _ = search_function(current_queries, temp_reference_db)\n",
    "            stop_time = time.time()\n",
    "            median_query_sequence_len = np.median([len(q) for q in current_queries])\n",
    "            median_reference_sequence_len = np.median([len(r) for r in temp_reference_db])\n",
    "            data.append((nq, nr, median_query_sequence_len, median_reference_sequence_len,\n",
    "                         stop_time - start_time))\n",
    "    runtimes = pd.DataFrame(data=np.asarray(data),\n",
    "                            columns=[\"Number of query seqs\", \"Number of reference seqs\",\n",
    "                                     \"Median query seq length\", \"Median reference seq length\",\n",
    "                                     \"Runtime (s)\"] )\n",
    "    return runtimes\n",
    "\n",
    "# we'll temporarily work with a smaller reference database\n",
    "# so this will run a lot faster. this will be of fixed size.\n",
    "n_reference_sequences = [100]\n",
    "# since our database is smaller, we can work with some slightly\n",
    "# larger numbers of sequences.\n",
    "n_query_sequences = [1, 5, 10, 15]\n",
    "\n",
    "local_alignment_search_runtimes = tabulate_local_alignment_search_runtime(queries, reference_db,\n",
    "                                                                          n_query_sequences, n_reference_sequences,\n",
    "                                                                          local_alignment_search)\n",
    "local_alignment_search_runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows that we've tried a few variations on number of query sequences but kept the number of reference sequences constant. There is no variance in the query sequence length, and there is a relatively small amount of variance in reference sequence length (they're all of the same order of magnitude). There is also relatively little variance in runtime for fixed numbers of query and reference sequences.\n",
    "\n",
    "This table clearly shows that there is an increase in runtime with an increasing number of query sequences, which we'd of course expect. What we care about is how runtime is increasing as a function of number of query sequences. Let's plot runtime versus the number of query sequences to help us understand that relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f22a6823be0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/home/runner/work/q2book/q2book/book/_build/jupyter_execute/algorithms/database-searching_28_1.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.regplot(x=\"Number of query seqs\", y=\"Runtime (s)\", data=local_alignment_search_runtimes)\n",
    "ax.set_xlim(0)\n",
    "ax.set_ylim(0)\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see here is pretty clearly a linear relationship: $runtime \\approx constant \\times number\\ of\\ query\\ sequences$. This is because as we increase the number of query sequences, we're increasing the number of pairwise alignments that we need to perform. If we have 5 queries and 10 reference sequences, we compute $5 \\times 10 = 50$ pairwise alignments. If we have 10 queries and 100 reference sequences, we compute $10 \\times 100 = 1000$ pairwise alignments. There are a few practical ways to reduce the runtime of a process like this.\n",
    "\n",
    "The first seems obvious, and even silly at first: perform fewer alignments. This could be achieved in a few ways. You could reduce the number of query sequences, though this might be something a researcher is resistant to: they have some collection of unknown sequences, and they want to know what they all are. You could alternatively reduce the number of reference sequences, but you might run into the same issues there: we wouldn't want to exclude reference sequences that might provide us with useful information about our query sequences. Finally, we might be able to figure out some ways to perform fewer alignments by not searching all of the query sequences against all of the reference sequences. If we could come up with some procedure to approximate which pairwise alignments were likely to be good (i.e., high scoring) and which were likely to be bad (i.e., low scoring) that is faster than performing the pairwise alignments, we could apply that procedure and only align a pair of sequences when we expect to get a high score. That could potentially allow us to reduce the number of alignments we need to perform, and therefore the runtime of the algorithm.\n",
    "\n",
    "Another approach to reducing the runtime of this process would be to create a faster implementation of the algorithm (though at some point that won't be possible anymore), use a faster computer, or run the process in parallel on multiple processors. All of these would be ways to reduce the runtime of the search by some factor $f$, where $new\\ runtime \\approx \\frac{runtime}{f}$.\n",
    "\n",
    "In practice, for a production-scale sequence database search application like BLAST, we'd combine these approaches. In the next section we'll explore ways to reduce the runtime of database searching for a fixed number of query sequences and a fixed number of reference sequences by reducing the number of pairwise alignments that the search function will perform.\n",
    "\n",
    "## Heuristic algorithms \n",
    "\n",
    "As mentioned above, it just takes too long to search individual query sequences against a large database. This problem also isn't going away anytime soon. While computers are getting faster (or cheaper), the size of our sequences collections are getting bigger because sequencing is getting cheaper. In fact, many people think that obtaining DNA sequences is getting cheaper faster than computers are getting cheaper. As our number of query sequences increases because we are able to obtain more for the same amount of money, and the size of our reference databases increases (because we're continuously obtaining more sequence data) this will increasingly become a bigger problem. Figures 1 and 2, respectively, illustrate that these are both real-world issues. Notice that the axes are on a log scale in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe\n",
       "    width=\"600\"\n",
       "    height=\"394\"\n",
       "    src=\"https://docs.google.com/spreadsheets/d/1vUkUuZsRlLW5U05rXXUn8B2sDYwShkClRMGa8Wiu6bc/pubchart?oid=1844125885&amp;format=interactive\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f22a6829ba8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display\n",
    "IPython.display.IFrame(width=\"600\", height=\"394\", src=\"https://docs.google.com/spreadsheets/d/1vUkUuZsRlLW5U05rXXUn8B2sDYwShkClRMGa8Wiu6bc/pubchart?oid=1844125885&amp;format=interactive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1: Genome sequencing costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe\n",
       "    width=\"763\"\n",
       "    height=\"371\"\n",
       "    src=\"https://docs.google.com/spreadsheets/d/1vUkUuZsRlLW5U05rXXUn8B2sDYwShkClRMGa8Wiu6bc/pubchart?oid=2103353397&amp;format=interactive\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f22a68297f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display\n",
    "IPython.display.IFrame(width=\"763\", height=\"371\", src=\"https://docs.google.com/spreadsheets/d/1vUkUuZsRlLW5U05rXXUn8B2sDYwShkClRMGa8Wiu6bc/pubchart?oid=2103353397&amp;format=interactive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2: Size of GenBank.\n",
    "\n",
    "One way that we can deal with this problem is by recognizing that most of the alignments that are performed in a database search are unlikely to be very good alignments. An algorithm developer could therefore improve runtime by defining a heuristic (or a rule) that is applied to determine which reference sequences are likely to result in good alignments, and only aligning the query against those. For it to be useful, making the decision to align or not (i.e., applying the heuristic) must be *much faster* than actually performing the pairwise alignment. The heuristic also needs to make *good* choices about which reference sequences to align the query against. If the algorithm chooses to not align against a specific reference, that reference is ruled out as a possible result of the database search. A good heuristic for sequence homology searching would therefore be very unlikely to exclude the best alignment(s). When thinking about heuristic algorithms in general, there are some important considerations:\n",
    "\n",
    "1. How often does the heuristic algorithm fail to get the right answer (in our case, does it make good choices about which reference sequences to align against)?\n",
    "2. How much faster is the heuristic than the \"complete\" approach, and is that reduction in runtime enough to justify not being guaranteed to get the best answer?\n",
    "\n",
    "We'll now look at a few heuristics in the context of these questions.\n",
    "\n",
    "### Random reference sequence selection \n",
    "\n",
    "Our first heuristic will be a [straw man](https://en.wikipedia.org/wiki/Straw_man) that we use as a baseline. We'll select a random $p\\%$ of the reference sequences to align our query against. This will clearly result in a large decrease in the number of sequence alignments that we need to perform because we'll go from performing $R_s$ (the reference database size) sequence alignments to $p \\times R_s$ sequence alignments for each query sequence $q_i$.\n",
    "\n",
    "Here's the source code for this. You can see that we're just wrapping our ``local_alignment_search`` function in a function that samples down to $p\\%$ of the reference sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def heuristic_local_alignment_search_random(\n",
    "        queries, reference_db, p, n=5, aligner=local_pairwise_align_ssw):\n",
    "    k = int(p * len(reference_db))\n",
    "    database_subset = random.sample(reference_db, k)\n",
    "    return local_alignment_search(queries, database_subset, n=n, aligner=aligner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select some new queries and see how the results compare to our known taxonomies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_queries = random.sample(queries, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest taxonomies for query 178839 (in order):\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__; g__; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__[Acidaminobacteraceae]; g__Guggenheimella; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Lachnospiraceae; g__Lachnospira; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Ruminococcaceae; g__; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Lachnospiraceae; g__; s__\n",
      "\n",
      "Closest taxonomies for query 203529 (in order):\n",
      "  k__Bacteria; p__Proteobacteria; c__Deltaproteobacteria; o__MIZ46; f__; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Epsilonproteobacteria; o__Campylobacterales; f__Helicobacteraceae; g__; s__\n",
      "  k__Bacteria; p__Verrucomicrobia; c__[Pedosphaerae]; o__[Pedosphaerales]; f__; g__; s__\n",
      "  k__Bacteria; p__OP3; c__BD4-9; o__; f__; g__; s__\n",
      "  k__Bacteria; p__Chlorobi; c__Ignavibacteria; o__Ignavibacteriales; f__[Melioribacteraceae]; g__; s__\n",
      "\n",
      "Closest taxonomies for query 813690 (in order):\n",
      "  k__Bacteria; p__Proteobacteria; c__Betaproteobacteria; o__Burkholderiales; f__Burkholderiaceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Betaproteobacteria; o__Burkholderiales; f__Burkholderiaceae; g__Salinispora; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Betaproteobacteria; o__Burkholderiales; f__; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Betaproteobacteria; o__SC-I-84; f__; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Betaproteobacteria; o__Methylophilales; f__Methylophilaceae; g__; s__\n",
      "\n",
      "Closest taxonomies for query 4473448 (in order):\n",
      "  k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Bacillaceae; g__Bacillus; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Bacillaceae; g__; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Sporolactobacillaceae; g__; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Bacillaceae; g__Anoxybacillus; s__kestanbolensis\n",
      "  k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Paenibacillaceae; g__Paenibacillus; s__\n",
      "\n",
      "Closest taxonomies for query 621303 (in order):\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhizobiales; f__Hyphomicrobiaceae; g__Rhodoplanes; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhizobiales; f__; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__; f__; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodospirillales; f__Rhodospirillaceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__; f__; g__; s__\n",
      "\n",
      "Closest taxonomies for query 817888 (in order):\n",
      "  k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Staphylococcaceae; g__Staphylococcus; s__aureus\n",
      "  k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Bacillaceae; g__Bacillus; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Bacillaceae; g__Anoxybacillus; s__kestanbolensis\n",
      "  k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Paenibacillaceae; g__Paenibacillus; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Bacillaceae; g__; s__\n",
      "\n",
      "Closest taxonomies for query 570490 (in order):\n",
      "  k__Bacteria; p__Verrucomicrobia; c__[Pedosphaerae]; o__[Pedosphaerales]; f__; g__; s__\n",
      "  k__Bacteria; p__Verrucomicrobia; c__Verruco-5; o__LD1-PB3; f__; g__; s__\n",
      "  k__Bacteria; p__Verrucomicrobia; c__Opitutae; o__Puniceicoccales; f__Puniceicoccaceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Chromatiales; f__Ectothiorhodospiraceae; g__; s__\n",
      "  k__Bacteria; p__Verrucomicrobia; c__Verrucomicrobiae; o__Verrucomicrobiales; f__Verrucomicrobiaceae; g__Luteolibacter; s__\n",
      "\n",
      "Closest taxonomies for query 578470 (in order):\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodospirillales; f__Rhodospirillaceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodospirillales; f__Rhodospirillaceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhizobiales; f__Hyphomicrobiaceae; g__Rhodoplanes; s__\n",
      "  k__Bacteria; p__Cyanobacteria; c__Oscillatoriophycideae; o__Chroococcales; f__Xenococcaceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodospirillales; f__Rhodospirillaceae; g__; s__\n",
      "\n",
      "Closest taxonomies for query 3030171 (in order):\n",
      "  k__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Enterobacteriales; f__Enterobacteriaceae; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rickettsiales; f__AEGEAN_112; g__; s__\n",
      "  k__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Alteromonadales; f__Colwelliaceae; g__; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Ruminococcaceae; g__; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Ruminococcaceae; g__; s__\n",
      "\n",
      "Closest taxonomies for query 195759 (in order):\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Lachnospiraceae; g__Blautia; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Lachnospiraceae; g__Roseburia; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Lachnospiraceae; g__[Ruminococcus]; s__\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Lachnospiraceae; g__[Ruminococcus]; s__gnavus\n",
      "  k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Lachnospiraceae; g__; s__\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = heuristic_local_alignment_search_random(current_queries, reference_db, p=0.10)\n",
    "\n",
    "for q in current_queries:\n",
    "    q_id = q.metadata['id']\n",
    "    print('Closest taxonomies for query %s (in order):' % q_id)\n",
    "    for e in results['reference taxonomy'][q_id]:\n",
    "        print(' ', e)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known taxonomy for query 178839:\n",
      " k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__[Mogibacteriaceae]; g__; s__\n",
      "Known taxonomy for query 203529:\n",
      " k__Bacteria; p__OD1; c__SM2F11; o__; f__; g__; s__\n",
      "Known taxonomy for query 813690:\n",
      " k__Bacteria; p__Proteobacteria; c__Betaproteobacteria; o__Burkholderiales; f__Comamonadaceae; g__; s__\n",
      "Known taxonomy for query 4473448:\n",
      " k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Thermoactinomycetaceae; g__; s__\n",
      "Known taxonomy for query 621303:\n",
      " k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhizobiales; f__Hyphomicrobiaceae; g__Pannonibacter; s__phragmitetus\n",
      "Known taxonomy for query 817888:\n",
      " k__Bacteria; p__Firmicutes; c__Bacilli; o__Bacillales; f__Bacillaceae; g__Bacillus; s__cereus\n",
      "Known taxonomy for query 570490:\n",
      " k__Bacteria; p__Verrucomicrobia; c__[Pedosphaerae]; o__[Pedosphaerales]; f__; g__; s__\n",
      "Known taxonomy for query 578470:\n",
      " k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodospirillales; f__Rhodospirillaceae; g__Inquilinus; s__\n",
      "Known taxonomy for query 3030171:\n",
      " k__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Enterobacteriales; f__Enterobacteriaceae; g__Candidatus Blochmannia; s__\n",
      "Known taxonomy for query 195759:\n",
      " k__Bacteria; p__Firmicutes; c__Clostridia; o__Clostridiales; f__Lachnospiraceae; g__; s__\n"
     ]
    }
   ],
   "source": [
    "for q in current_queries:\n",
    "    q_id = q.metadata['id']\n",
    "    print('Known taxonomy for query %s:\\n %s' % (q_id, reference_taxonomy[q_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need now is a way to know how often we get the \"right answer\", and how long this heuristic algorithm takes relative to the complete algorithm. We therefore first need to define what the \"right answer\" is. How about this: if the most common taxonomy assignment resulting from the database search at `taxonomy_levels` levels of taxonomy (i.e., how deep or specific our assignment is) matches the known taxonomy, then our algorithm has achieved the right answer. We can vary `taxonomy_levels` to see how the different heuristics perform at different levels.\n",
    "\n",
    "Here's what this would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def evaluate_search(queries, reference_db, reference_taxonomy, search_function, taxonomy_levels, n=5, aligner=local_pairwise_align_ssw):\n",
    "    start_time = time.time()\n",
    "    search_results = search_function(current_queries, reference_db, n=n, aligner=aligner)\n",
    "    stop_time = time.time()\n",
    "    runtime = stop_time - start_time\n",
    "    per_query_runtime = runtime/len(queries)\n",
    "    data = []\n",
    "    indices = []\n",
    "    for q in queries:\n",
    "        q_id = q.metadata['id']\n",
    "        indices.append(q_id)\n",
    "        q_known_taxonomy = tuple(reference_taxonomy[q_id].split('; ')[:taxonomy_levels])\n",
    "        q_observed_taxonomies = collections.Counter()\n",
    "        for e in search_results['reference taxonomy'][q_id]:\n",
    "            q_observed_taxonomies[tuple(e.split('; ')[:taxonomy_levels])] += 1\n",
    "        q_observed_taxonomy = q_observed_taxonomies.most_common()[0][0]\n",
    "        data.append((q_known_taxonomy, q_observed_taxonomy))\n",
    "    index = pd.Index(indices, name='Query ID')\n",
    "    data = pd.DataFrame(data, index=index, columns=['Known taxonomy', 'Observed taxonomy'])\n",
    "    number_correct = np.sum(data['Known taxonomy'] == data['Observed taxonomy'])\n",
    "    fraction_correct = number_correct / data.shape[0]\n",
    "    return per_query_runtime, fraction_correct, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's see how this works for our full database search algorithm. What's the runtime, and how often do we get the correct answer? We'll start with five levels of taxonomy (which corresponds to the family level). **This step will take a couple of minutes to run, because it's doing the full database search.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_levels = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.97 seconds per query sequence\n",
      "70.00% correct answers\n",
      "Result details:\n",
      "178839\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__[Mogibacteriaceae]')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Clostridiaceae')\n",
      "\n",
      "203529\n",
      "  ('k__Bacteria', 'p__OD1', 'c__SM2F11', 'o__', 'f__')\n",
      "  ('k__Bacteria', 'p__OD1', 'c__SM2F11', 'o__', 'f__')\n",
      "\n",
      "813690\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Betaproteobacteria', 'o__Burkholderiales', 'f__Comamonadaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Betaproteobacteria', 'o__Burkholderiales', 'f__Comamonadaceae')\n",
      "\n",
      "4473448\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Thermoactinomycetaceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "\n",
      "621303\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhizobiales', 'f__Hyphomicrobiaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhizobiales', 'f__')\n",
      "\n",
      "817888\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "\n",
      "570490\n",
      "  ('k__Bacteria', 'p__Verrucomicrobia', 'c__[Pedosphaerae]', 'o__[Pedosphaerales]', 'f__')\n",
      "  ('k__Bacteria', 'p__Verrucomicrobia', 'c__[Pedosphaerae]', 'o__[Pedosphaerales]', 'f__')\n",
      "\n",
      "578470\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "\n",
      "3030171\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Gammaproteobacteria', 'o__Enterobacteriales', 'f__Enterobacteriaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Gammaproteobacteria', 'o__Enterobacteriales', 'f__Enterobacteriaceae')\n",
      "\n",
      "195759\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Lachnospiraceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Lachnospiraceae')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runtime, fraction_correct, data = evaluate_search(current_queries, reference_db, reference_taxonomy,\n",
    "                                                  local_alignment_search, taxonomy_levels=taxonomy_levels)\n",
    "print('%1.2f seconds per query sequence' % runtime)\n",
    "print('%1.2f%% correct answers' % (fraction_correct * 100.0))\n",
    "print('Result details:')\n",
    "for q_id in data.index:\n",
    "    print(q_id)\n",
    "    print(' ', data['Known taxonomy'][q_id])\n",
    "    print(' ', data['Observed taxonomy'][q_id])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's see how this compares to our random heuristic search algorithm. Try running this a few times, as you might get different answers due to different random selections of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40 seconds per query sequence\n",
      "50.00% correct answers\n",
      "Result details:\n",
      "178839\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__[Mogibacteriaceae]')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Lachnospiraceae')\n",
      "\n",
      "203529\n",
      "  ('k__Bacteria', 'p__OD1', 'c__SM2F11', 'o__', 'f__')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Deltaproteobacteria', 'o__Myxococcales', 'f__')\n",
      "\n",
      "813690\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Betaproteobacteria', 'o__Burkholderiales', 'f__Comamonadaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Betaproteobacteria', 'o__Burkholderiales', 'f__Comamonadaceae')\n",
      "\n",
      "4473448\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Thermoactinomycetaceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "\n",
      "621303\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhizobiales', 'f__Hyphomicrobiaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "\n",
      "817888\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "\n",
      "570490\n",
      "  ('k__Bacteria', 'p__Verrucomicrobia', 'c__[Pedosphaerae]', 'o__[Pedosphaerales]', 'f__')\n",
      "  ('k__Bacteria', 'p__Verrucomicrobia', 'c__[Spartobacteria]', 'o__[Chthoniobacterales]', 'f__[Chthoniobacteraceae]')\n",
      "\n",
      "578470\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "\n",
      "3030171\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Gammaproteobacteria', 'o__Enterobacteriales', 'f__Enterobacteriaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Gammaproteobacteria', 'o__Enterobacteriales', 'f__Enterobacteriaceae')\n",
      "\n",
      "195759\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Lachnospiraceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Lachnospiraceae')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "heuristic_local_alignment_search_random_10 = functools.partial(heuristic_local_alignment_search_random, p=0.10)\n",
    "\n",
    "runtime, fraction_correct, data = evaluate_search(current_queries, reference_db, reference_taxonomy,\n",
    "                                                  heuristic_local_alignment_search_random_10, taxonomy_levels=taxonomy_levels)\n",
    "\n",
    "print('%1.2f seconds per query sequence' % runtime)\n",
    "print('%1.2f%% correct answers' % (fraction_correct * 100.0))\n",
    "print('Result details:')\n",
    "for q_id in data.index:\n",
    "    print(q_id)\n",
    "    print(' ', data['Known taxonomy'][q_id])\n",
    "    print(' ', data['Observed taxonomy'][q_id])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, what's the runtime, and how often do we get the correct answer? Based on comparison to the full search, what do you think: is this a good heuristic?\n",
    "\n",
    "After performing many trials of the above searches, I get the correct genus-level assignment about half as often with the random reference database heuristic relative to the full database search. Your results might differ from that due to differences in the random selection of query and reference sequences. Try running all the cells in this section a few times.\n",
    "\n",
    "Go back to the beginning of this section and try running this check based on fewer levels of taxonomy (i.e., decreased taxonomic specificity, such as the phylum) and on more levels of taxonomy (i.e., increased taxonomic specificity, such as the species level). How does that impact how often we get the right answer?\n",
    "\n",
    "### Composition-based reference sequence collection \n",
    "\n",
    "While the random selection of database sequences can vastly reduce the runtime for database searching, we don't get the right answer very often. Let's try some heuristics that are a bit smarter. How about this: if the overall nucleotide composition of a query sequence is very different than the overall nucleotide composition of a reference sequence, it's unlikely that the best alignment will result from that pairwise alignment, so don't align the query to that reference sequence. Given that, how do we define \"overall nucleotide composition\" in a useful way?\n",
    "\n",
    "#### GC content \n",
    "\n",
    "One metric of sequence composition that we can compute quickly (because remember, this has to be a lot faster than computing the alignment for it to be worth it) is GC content. Let's define a heuristic that only performs a pairwise alignment for the reference sequences that have the most similar GC content to the query sequence. The number of alignments that we'll perform will be defined as ``database_subset_size``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_subset_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_local_alignment_search_gc(\n",
    "        queries, reference_db, database_subset_size, n=5,\n",
    "        reference_db_gc_contents=None,\n",
    "        aligner=local_pairwise_align_ssw):\n",
    "    results = []\n",
    "    if reference_db_gc_contents is None:\n",
    "        reference_db_gc_contents = \\\n",
    "         {r.metadata['id'] : r.gc_content() for r in reference_db}\n",
    "    for q in queries:\n",
    "        query_gc_content = q.gc_content()\n",
    "        database_subset = []\n",
    "        for r in reference_db:\n",
    "            ref_gc_content = reference_db_gc_contents[r.metadata['id']]\n",
    "            # find the difference in GC content between the reference and\n",
    "            # query. we'll sort and select our reference sequences by this\n",
    "            # value\n",
    "            database_subset.append((abs(ref_gc_content - query_gc_content), r))\n",
    "        database_subset.sort(key=lambda x: x[0])\n",
    "        database_subset = [e[1] for e in database_subset[:database_subset_size]]\n",
    "        results.append(local_alignment_search(\n",
    "            [q], database_subset, n=n, aligner=aligner))\n",
    "    return pd.concat(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run our queries again, how often do we get the right answer? How much did we reduce runtime? Do you think this is a better or worse heuristic than what we implemented above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42 seconds per query sequence\n",
      "50.00% correct answers\n",
      "Result details:\n",
      "178839\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__[Mogibacteriaceae]')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Peptostreptococcaceae')\n",
      "\n",
      "203529\n",
      "  ('k__Bacteria', 'p__OD1', 'c__SM2F11', 'o__', 'f__')\n",
      "  ('k__Bacteria', 'p__OD1', 'c__SM2F11', 'o__', 'f__')\n",
      "\n",
      "813690\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Betaproteobacteria', 'o__Burkholderiales', 'f__Comamonadaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Betaproteobacteria', 'o__SC-I-84', 'f__')\n",
      "\n",
      "4473448\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Thermoactinomycetaceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Paenibacillaceae')\n",
      "\n",
      "621303\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhizobiales', 'f__Hyphomicrobiaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "\n",
      "817888\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "\n",
      "570490\n",
      "  ('k__Bacteria', 'p__Verrucomicrobia', 'c__[Pedosphaerae]', 'o__[Pedosphaerales]', 'f__')\n",
      "  ('k__Bacteria', 'p__Verrucomicrobia', 'c__Verruco-5', 'o__LD1-PB3', 'f__')\n",
      "\n",
      "578470\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "\n",
      "3030171\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Gammaproteobacteria', 'o__Enterobacteriales', 'f__Enterobacteriaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Gammaproteobacteria', 'o__Enterobacteriales', 'f__Enterobacteriaceae')\n",
      "\n",
      "195759\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Lachnospiraceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Lachnospiraceae')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heuristic_local_alignment_search_gc_2 = functools.partial(heuristic_local_alignment_search_gc, database_subset_size=database_subset_size)\n",
    "\n",
    "runtime, fraction_correct, data = evaluate_search(current_queries, reference_db, reference_taxonomy,\n",
    "                                                  heuristic_local_alignment_search_gc_2, taxonomy_levels=taxonomy_levels)\n",
    "\n",
    "print('%1.2f seconds per query sequence' % runtime)\n",
    "print('%1.2f%% correct answers' % (fraction_correct * 100.0))\n",
    "print('Result details:')\n",
    "for q_id in data.index:\n",
    "    print(q_id)\n",
    "    print(' ', data['Known taxonomy'][q_id])\n",
    "    print(' ', data['Observed taxonomy'][q_id])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try increasing and decreasing the number of sequences we'll align by increasing or decreasing ``database_subset_size``. How does this impact the runtime and fraction of time that we get the correct answer?\n",
    "\n",
    "#### kmer content \n",
    "\n",
    "Another metric of sequence composition is *kmer composition*. A kmer is simply a word (or list of adjacent characters) of length *k* found within a sequence. Here are the kmer frequencies in a short DNA sequence. The ``overlap=True`` parameter here means that our kmers can overlap one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACCGT': 1,\n",
       " 'CCGTG': 1,\n",
       " 'CGTGA': 1,\n",
       " 'GTGAC': 1,\n",
       " 'TGACC': 2,\n",
       " 'GACCA': 2,\n",
       " 'ACCAG': 2,\n",
       " 'CCAGT': 2,\n",
       " 'CAGTT': 2,\n",
       " 'AGTTA': 1,\n",
       " 'GTTAC': 1,\n",
       " 'TTACC': 1,\n",
       " 'TACCA': 1,\n",
       " 'AGTTT': 1,\n",
       " 'GTTTG': 1,\n",
       " 'TTTGA': 1,\n",
       " 'TTGAC': 1,\n",
       " 'ACCAA': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skbio\n",
    "\n",
    "skbio.DNA('ACCGTGACCAGTTACCAGTTTGACCAA').kmer_frequencies(k=5, overlap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our next heuristic, we'll only align our query to the reference sequences with the largest fraction of the kmers that are observed in the query sequence are also present in the reference sequence. This makes a lot of sense to use as an alignment heuristic: we're only aligning sequences when it looks like they'll have multiple length-``k`` stretches of nucleotides that are not interrupted by substitutions or insertion/deletion mutations.\n",
    "\n",
    "In our next heuristic, we'll only align our query to the reference sequences with the largest fraction of the kmers that are observed in the query sequence. This makes a lot of sense to use as an alignment heuristic: we're only aligning sequences when it looks like they'll have multiple length-``k`` stretches of nucleotides that are not interrupted by substitutions or insertion/deletion mutations.\n",
    "\n",
    "\n",
    "Here's the source code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraction_shared_kmers(kmer_freqs1, kmer_freqs2):\n",
    "    \"\"\"Compute the fraction of kmers in kmer_freqs1 that are also in kmer_freqs2\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmer_freqs1, kmer_freqs2\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If k < 1.\n",
    "    Notes\n",
    "    -----\n",
    "    k-mer counts are not incorporated in this distance metric.\n",
    "    \"\"\"\n",
    "    sequence1_kmers = set(kmer_freqs1)\n",
    "    num_sequence1_kmers = len(sequence1_kmers)\n",
    "    sequence2_kmers = set(kmer_freqs2)\n",
    "    shared_kmers = sequence1_kmers & sequence2_kmers\n",
    "    return len(shared_kmers) / num_sequence1_kmers\n",
    "\n",
    "def heuristic_local_alignment_search_kmers(\n",
    "        queries, reference_db, database_subset_size, k, n=5,\n",
    "        reference_db_kmer_frequencies=None,\n",
    "        aligner=local_pairwise_align_ssw):\n",
    "    results = []\n",
    "    if reference_db_kmer_frequencies is None:\n",
    "        reference_db_kmer_frequencies = \\\n",
    "         {r.metadata['id'] : r.kmer_frequencies(k=k, overlap=True) for r in reference_db}\n",
    "    for q in queries:\n",
    "        query_kmer_frequency = q.kmer_frequencies(k=k, overlap=True)\n",
    "        database_subset = []\n",
    "        for r in reference_db:\n",
    "            ref_kmer_frequency = reference_db_kmer_frequencies[r.metadata['id']]\n",
    "            s = fraction_shared_kmers(query_kmer_frequency, ref_kmer_frequency)\n",
    "            database_subset.append((s, r))\n",
    "        database_subset.sort(key=lambda x: x[0], reverse=True)\n",
    "        database_subset = [e[1] for e in database_subset[:database_subset_size]]\n",
    "        results.append(local_alignment_search(\n",
    "            [q], database_subset, n=n, aligner=aligner))\n",
    "    return pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this and see how it does. How does the runtime and fraction of correct assignments compare to our GC content-based search and our full database search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.88 seconds per query sequence\n",
      "70.00% correct answers\n",
      "Result details:\n",
      "178839\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__[Mogibacteriaceae]')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Clostridiaceae')\n",
      "\n",
      "203529\n",
      "  ('k__Bacteria', 'p__OD1', 'c__SM2F11', 'o__', 'f__')\n",
      "  ('k__Bacteria', 'p__OD1', 'c__SM2F11', 'o__', 'f__')\n",
      "\n",
      "813690\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Betaproteobacteria', 'o__Burkholderiales', 'f__Comamonadaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Betaproteobacteria', 'o__Burkholderiales', 'f__Comamonadaceae')\n",
      "\n",
      "4473448\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Thermoactinomycetaceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "\n",
      "621303\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhizobiales', 'f__Hyphomicrobiaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhizobiales', 'f__')\n",
      "\n",
      "817888\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "\n",
      "570490\n",
      "  ('k__Bacteria', 'p__Verrucomicrobia', 'c__[Pedosphaerae]', 'o__[Pedosphaerales]', 'f__')\n",
      "  ('k__Bacteria', 'p__Verrucomicrobia', 'c__[Pedosphaerae]', 'o__[Pedosphaerales]', 'f__')\n",
      "\n",
      "578470\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "\n",
      "3030171\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Gammaproteobacteria', 'o__Enterobacteriales', 'f__Enterobacteriaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Gammaproteobacteria', 'o__Enterobacteriales', 'f__Enterobacteriaceae')\n",
      "\n",
      "195759\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Lachnospiraceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Lachnospiraceae')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heuristic_local_alignment_search_kmers_50 = \\\n",
    "functools.partial(heuristic_local_alignment_search_kmers, k=k, database_subset_size=database_subset_size)\n",
    "\n",
    "runtime, fraction_correct, data = evaluate_search(current_queries, reference_db, reference_taxonomy,\n",
    "                                                  heuristic_local_alignment_search_kmers_50,\n",
    "                                                  taxonomy_levels=taxonomy_levels)\n",
    "\n",
    "print('%1.2f seconds per query sequence' % runtime)\n",
    "print('%1.2f%% correct answers' % (fraction_correct * 100.0))\n",
    "print('Result details:')\n",
    "for q_id in data.index:\n",
    "    print(q_id)\n",
    "    print(' ', data['Known taxonomy'][q_id])\n",
    "    print(' ', data['Observed taxonomy'][q_id])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further optimizing composition-based approaches by pre-computing reference database information \n",
    "\n",
    "One important feature of composition-based approaches is that, because the reference database doesn't change very often, we can pre-compute features of the reference sequences and re-use them. This can help us to vastly decrease the runtime of our heuristic searches. For example, the computation of all of the reference database kmer frequencies is a lot of work. If we can compute that outside of our database search, we can avoid doing that step for every database search, and therefore remove that computationally expensive (i.e., slow) step of the process.\n",
    "\n",
    "Here we'll compute all of the reference database kmer frequencies. Notice that this step takes about a minute to complete. This is a minute of compute time that we can save on every database search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_db_kmer_frequencies = {r.metadata['id']: r.kmer_frequencies(k=k, overlap=True) for r in reference_db}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now pass our pre-computed kmer frequencies into our search function. How does the runtime and accuracy of this search compare to the searches above? This last database search that we've implemented here is very similar to how BLAST works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70 seconds per query sequence\n",
      "70.00% correct answers\n",
      "Result details:\n",
      "178839\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__[Mogibacteriaceae]')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Clostridiaceae')\n",
      "\n",
      "203529\n",
      "  ('k__Bacteria', 'p__OD1', 'c__SM2F11', 'o__', 'f__')\n",
      "  ('k__Bacteria', 'p__OD1', 'c__SM2F11', 'o__', 'f__')\n",
      "\n",
      "813690\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Betaproteobacteria', 'o__Burkholderiales', 'f__Comamonadaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Betaproteobacteria', 'o__Burkholderiales', 'f__Comamonadaceae')\n",
      "\n",
      "4473448\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Thermoactinomycetaceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "\n",
      "621303\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhizobiales', 'f__Hyphomicrobiaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhizobiales', 'f__')\n",
      "\n",
      "817888\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Bacilli', 'o__Bacillales', 'f__Bacillaceae')\n",
      "\n",
      "570490\n",
      "  ('k__Bacteria', 'p__Verrucomicrobia', 'c__[Pedosphaerae]', 'o__[Pedosphaerales]', 'f__')\n",
      "  ('k__Bacteria', 'p__Verrucomicrobia', 'c__[Pedosphaerae]', 'o__[Pedosphaerales]', 'f__')\n",
      "\n",
      "578470\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Alphaproteobacteria', 'o__Rhodospirillales', 'f__Rhodospirillaceae')\n",
      "\n",
      "3030171\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Gammaproteobacteria', 'o__Enterobacteriales', 'f__Enterobacteriaceae')\n",
      "  ('k__Bacteria', 'p__Proteobacteria', 'c__Gammaproteobacteria', 'o__Enterobacteriales', 'f__Enterobacteriaceae')\n",
      "\n",
      "195759\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Lachnospiraceae')\n",
      "  ('k__Bacteria', 'p__Firmicutes', 'c__Clostridia', 'o__Clostridiales', 'f__Lachnospiraceae')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heuristic_local_alignment_search_kmers_50 = \\\n",
    " functools.partial(heuristic_local_alignment_search_kmers, reference_db_kmer_frequencies=reference_db_kmer_frequencies,\n",
    "                   k=k, database_subset_size=database_subset_size)\n",
    "\n",
    "runtime, fraction_correct, data = evaluate_search(current_queries, reference_db, reference_taxonomy,\n",
    "                                                  heuristic_local_alignment_search_kmers_50,\n",
    "                                                  taxonomy_levels=taxonomy_levels)\n",
    "\n",
    "print('%1.2f seconds per query sequence' % runtime)\n",
    "print('%1.2f%% correct answers' % (fraction_correct * 100.0))\n",
    "print('Result details:')\n",
    "for q_id in data.index:\n",
    "    print(q_id)\n",
    "    print(' ', data['Known taxonomy'][q_id])\n",
    "    print(' ', data['Observed taxonomy'][q_id])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the statistical significance of a pairwise alignment \n",
    "\n",
    "One thing you may have noticed is that the score you get back for a pairwise alignment is hard to interpret. It's dependent on the query and reference sequence lengths (and possibly their composition, depending on your substitution matrix). So an important question is how to determine *how good* a given pairwise alignment is. Here we'll learn about a statistical approach for answering that.\n",
    "\n",
    "### Metrics of alignment quality \n",
    "\n",
    "In the examples above, we compared features such as how long the alignment is (relevant for local but not global alignment), the pairwise similarity between the aligned query and reference, and the score. If you've used a system like BLAST, you'll know that there are other values that are often reported about an alignment, like the number of substitutions, or the number of insertion/deletion (or gap) positions. None of these metrics are useful on their own. Let's look at an example to see why.\n",
    "\n",
    "Imagine we're aligning these two sequences:\n",
    "\n",
    "```\n",
    "GAAGCAGCAC\n",
    "GAACAGAAC\n",
    "```\n",
    "\n",
    "If we tell our search algorithm that we're interested in the alignment with the fewest number of substitutions, the following alignment would get us zero substitutions, but there are a lot of bases that look homologous which are not aligned.\n",
    "\n",
    "```\n",
    "GAAGCAGCAC-----\n",
    "GAA------CAGAAC\n",
    "```\n",
    "\n",
    "On the other hand, if we want to find the alignment with the fewest number of gaps, this one would get us that result, but we now have a lot of substitution events, and some regions that clearly look misaligned (such as the ``CAG`` sequence in the middle of both).\n",
    "\n",
    "```\n",
    "GAAGCAGCAC\n",
    "GAACAGA-AC\n",
    "```\n",
    "\n",
    "The alignment score that has been reported by our pairwise aligners helps us to balance these different features, and we can adjust the scoring scheme to weight things differently (e.g., so that gaps are penalized more or less than certain substitutions). The problem is that the scores are hard to interpret, particularly when we have only one or a few of them.\n",
    "\n",
    "### False positives, false negatives, p-values, and alpha  \n",
    "\n",
    "Remember that an alignment of a pair of sequences represents a hypothesis about homology between those sequences. One way that we think about determining if an alignment is good or not is to ask: *what fraction of the time would I obtain a score at least this good if my sequences are not homologous?* This fraction is usually referred to as our *p-value*, and this is computed in many different ways. If our p-value is high (e.g., 25%), then our alignment is probably not very good since it means that many non-homologous pairs of sequences would achieve a score at least that high. If our p-value is low (say 0.001%), then our alignment is probably good since scores that high are achieved only infrequently.\n",
    "\n",
    "Our threshold for defining what we consider to be a high versus low p-value is dependent on how often we're willing to be wrong. We would set this value, which is usually referred to as $\\alpha$, to some fraction, and if our p-value is less than $\\alpha$, we say that the alignment is statistically significant. If our p-value is greater than $\\alpha$, we say that our alignment is not statistically significant.\n",
    "\n",
    "There are a couple of ways that we could be wrong when we do sequence homology searching, and we need to consider these when we determine what value we want to define as $\\alpha$. First, we could say a pair of sequences are homologous when they're not, which would be a *false positive* or a *type 1 error*. Or, we could say that a pair of sequences are not homologous when they are, which would be a *false negative*, or a *type 2 error*.\n",
    "\n",
    "If incurring a false positive about 5% of the time is acceptable (i.e., you're ok with calling a pair of sequences homologous when they actually are not about one in twenty times) then you'd set your $\\alpha$ to 0.05. Setting $\\alpha$ to a value this high likely means that the method will err on the side of false positives, and only infrequently will it say that a pair of sequences are not homologous when they actually are (i.e., achieve a false negative). If $\\alpha$ were set to be very low on the other hand (say, $1 \\times 10^{-50}$), then you will err on the side of false negatives. Only infrequently will you say that a pair of non-homologous sequences are homologous, but you might call many pairs of homologous sequences non-homologous. You should think of $\\alpha$ as a dial. If you turn the dial toward higher values, you'll increase your false positive rate and decrease your false negative rate. If you turn the dial toward lower values, you'll decrease your false positive rate and increase your false negative rate.\n",
    "\n",
    "There is not a hard-and-fast rule for whether false positives or false negatives are better, which makes choosing $\\alpha$ hard. It's application specific, so you need to understand the biological question your asking when making this decision, and the ramifications of false positives versus false negatives. In general, when might you prefer to have false positives? When might you prefer to have false negatives?\n",
    "\n",
    "### Interpreting alignment scores in context \n",
    "\n",
    "In this section, we are going to learn about how to interpret alignment scores by empirically determining if a pairwise alignment that we obtain is better than we would expect if the pair of sequences we're working with were definitely not homologous. For a given pair of sequences that we want to align, we're first going to align them and compute the score of the alignment. We're then going to align many pairs of sequences that are similar to the query and reference, but that we know are not homologous. We'll do this by shuffling or randomizing the order of the bases in the query sequences, and performing another pairwise alignment.\n",
    "\n",
    "First, we'll define a function that can generate random sequences for us. This will take a scikit-bio sequence object (either ``skbio.DNA``, ``skbio.RNA``, or ``skbio.Protein``) and a length, and it will randomly generate a sequence of that type and length for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_sequence(moltype, length):\n",
    "    result = []\n",
    "    alphabet = list(moltype.nondegenerate_chars)\n",
    "    for e in range(length):\n",
    "        result.append(random.choice(alphabet))\n",
    "    return moltype(''.join(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run this a few times to generate some random sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "--------------------------------------------------------\n",
       "Stats:\n",
       "    length: 50\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 40.00%\n",
       "--------------------------------------------------------\n",
       "0 GTATACCTAA GCTAGATACT TGAGATGGTC ATAGGATAAC GGCCTACATT"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sequence(skbio.DNA, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "--------------------------------------------------------\n",
       "Stats:\n",
       "    length: 50\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 58.00%\n",
       "--------------------------------------------------------\n",
       "0 GCGCGCAGCA AGAATGCGCA TGCTAGCGTC ATCGCCTTGG CAAAGGTTCT"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sequence(skbio.DNA, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a function that will shuffle the characters in a sequence, and give us a new sequence back. We'll use this to generate a sequence that is similar (in length and composition) to our input sequence, but which we know is not homologous. We'll use Pythons `random.shuffle` function, which randomly re-orders the order of the elements in a sequence, but keeps the composition and length of the sequence the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_sequence(sequence):\n",
    "    # generate a list of the position indices (numbers) in sequence\n",
    "    randomized_order = list(range(len(sequence)))\n",
    "    # randomly rearrange the order of that list\n",
    "    random.shuffle(randomized_order)\n",
    "    # return a new sequence, where the positions are shuffled\n",
    "    return sequence[randomized_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a random sequence and shuffle it. Notice how the sequences are different (in their order), but their compositions (e.g., length and GC content) are the same. Shuffling will change the order of the bases, but it won't change the frequency at which each base is present - it's exactly analogous to shuffling a deck of cards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "--------------------------------------------------------\n",
       "Stats:\n",
       "    length: 50\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 64.00%\n",
       "--------------------------------------------------------\n",
       "0 TGTGGCCGGC TGTCAGTGGC GGACCGGACC CCTGGCGGAA ACATCTTAAC"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = random_sequence(skbio.DNA, 50)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "--------------------------------------------------------\n",
       "Stats:\n",
       "    length: 50\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 64.00%\n",
       "--------------------------------------------------------\n",
       "0 TGTAGAGCAG GCTCCGGAAC CCCGACGGGG TCGCCCAAGT GTGATTCTCG"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle_sequence(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a random query sequence and align it against itself to see what that score would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 100.00\n"
     ]
    }
   ],
   "source": [
    "query_seq = random_sequence(skbio.DNA, 50)\n",
    "_, actual_score, _ = local_pairwise_align_ssw(query_seq, query_seq)\n",
    "print(\"Score: %1.2f\" % actual_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's generate 99 random variants of that sequence with ``shuffle_sequence`` and compute the pairwise alignment for each of those variants against the query sequence. We'll then look at the distribution of those scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_score_distribution(sequence1,\n",
    "                                       sequence2,\n",
    "                                       n=99,\n",
    "                                       aligner=local_pairwise_align_ssw):\n",
    "    scores = []\n",
    "    # iterate n times\n",
    "    for i in range(n):\n",
    "        # generate a randomized version of the first sequence\n",
    "        random_sequence = shuffle_sequence(sequence1)\n",
    "        # align that randomized sequence against the second sequence\n",
    "        # and save its score\n",
    "        _, score, _ = aligner(random_sequence, sequence2)\n",
    "        scores.append(score)\n",
    "    # return the n randomized alignment scores\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 10, 10, 12, 10, 11, 12, 13, 12, 14, 13, 11, 9, 12, 11, 10, 14, 8, 12, 11, 12, 10, 10, 11, 12, 13, 9, 14, 12, 10, 12, 15, 11, 9, 10, 12, 12, 10, 12, 11, 9, 10, 12, 8, 10, 11, 12, 12, 12, 13, 9, 13, 8, 12, 13, 12, 11, 12, 8, 10, 14, 8, 13, 18, 13, 11, 13, 15, 10, 10, 12, 12, 9, 12, 13, 11, 11, 11, 12, 12, 12, 11, 13, 10, 10, 10, 12, 12, 12, 10, 12, 10, 14, 12, 14, 9, 15, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "random_scores = generate_random_score_distribution(query_seq, query_seq, 99)\n",
    "print(random_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the actual score of aligning the sequence to itself compare to the score of aligning it to many similar but non-homologous sequences? Let's plot these to get a better idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_score_distribution(actual_score, random_scores):\n",
    "    ax = sns.distplot(random_scores, kde=False, label=\"Random scores\", color=\"b\")\n",
    "    ax.plot([actual_score, actual_score], ax.get_ylim(), '--', label=\"Actual score\")\n",
    "    # set the range of the x axis to be zero through 110% of the actual score\n",
    "    ax.set_xlim(0, actual_score + actual_score * 0.1)\n",
    "    ax.legend(loc=9, fontsize='large')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/miniconda/envs/q2book/lib/python3.6/site-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f22a640e5f8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/home/runner/work/q2book/q2book/book/_build/jupyter_execute/algorithms/database-searching_79_2.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_score_distribution(actual_score, random_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this tell us about our alignment score and therefore about our alignment? Is it good or bad?\n",
    "\n",
    "We finally have information that we can use to evaluate an alignment score, and therefore to evaluate the quality of an alignment. Let's use this information to quantify the quality of the alignment by computing a p-value. As we described above, this is simply the probability that we would obtain an alignment score at least this good if the sequences being aligned are not homologous. Since we have a lot of scores now from sequences that are similar but not homologous, if we just count how many are at least as high as our actual score and divide by the number of scores we compute, that is an empirical (data-driven) way of determining our p-value.\n",
    "\n",
    "To determine if our alignment is statistically significant, we need to define $\\alpha$ before computing the p-value so the p-value does not impact our choice of $\\alpha$. Let's define $\\alpha$ as 0.05. This choice means if we obtain a p-value less than 0.05 we will consider the alignment statistically significant and accept the hypothesis that the sequences are homologous.\n",
    "\n",
    "Here's what all of this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_score_distribution(sequence1,\n",
    "                                       sequence2,\n",
    "                                       n=99,\n",
    "                                       aligner=local_pairwise_align_ssw):\n",
    "    scores = []\n",
    "    # iterate n times\n",
    "    for i in range(n):\n",
    "        # generate a randomized version of the first sequence\n",
    "        random_sequence = shuffle_sequence(sequence1)\n",
    "        # align that randomized sequence against the second sequence\n",
    "        # and save its score\n",
    "        _, score, _ = aligner(random_sequence, sequence2)\n",
    "        scores.append(score)\n",
    "    # return the n randomized alignment scores\n",
    "    return scores\n",
    "\n",
    "def fraction_better_or_equivalent_alignments(sequence1,\n",
    "                                             sequence2,\n",
    "                                             n = 99,\n",
    "                                             aligner=local_pairwise_align_ssw):\n",
    "    # align sequence1 and sequence2 and store the score of the alignment\n",
    "    _, actual_score, _ = aligner(sequence1, sequence2)\n",
    "    # compute the distribution of randomized scores\n",
    "    random_scores = generate_random_score_distribution(sequence1,\n",
    "                                                       sequence2,\n",
    "                                                       n,\n",
    "                                                       aligner=aligner)\n",
    "\n",
    "    # count the number of random scores that are at least as good as our\n",
    "    # actual score\n",
    "    count_better = 0\n",
    "    for s in random_scores:\n",
    "        if s >= actual_score:\n",
    "            count_better += 1\n",
    "    # return the number of times we observe a score at least as good as the\n",
    "    # random score divided by the number of scores we computed. we add one\n",
    "    # to the numerator and denominator to account for our actual_score\n",
    "    return (count_better + 1) / (n + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of alignment scores at least as good as the alignment score: 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"Fraction of alignment scores at least as good as the alignment score: %r\" %\n",
    "      fraction_better_or_equivalent_alignments(query_seq, query_seq, 99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraction that we get back here is ``0.01``, which is lower than $\\alpha$, so we would accept the hypothesis that our sequences are homologous.\n",
    "\n",
    "A few notes on these empirically defined p-values. First, here's what the formula for computing this looks like:\n",
    "\n",
    "$p\\ value = \\frac{number\\ of\\ computed\\ aligned\\ scores\\ greater\\ than\\ or\\ equal\\ to\\ the\\ actual\\ alignment\\ score}{number\\ of\\ alignment\\ scores\\ computed}$\n",
    "\n",
    "The numerator and the denominator both include the actual alignment score, so the lowest p-value that can be achieved is $\\frac{1}{99 + 1}$, where the $1$ in the numerator corresponds to our actual alignment score (which is of course equal to itself), where the $99$ in the denominator is the number of permutations, and the $1$ in the denominator is a constant which corresponds the computation of the actual score. If we increase the number of permutations, say to 999, we could achieve greater precision (more significant digits) in our p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of alignment scores at least as good as the alignment score: 0.001\n"
     ]
    }
   ],
   "source": [
    "print(\"Fraction of alignment scores at least as good as the alignment score: %r\" %\n",
    "      fraction_better_or_equivalent_alignments(query_seq, query_seq, 999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we achieve the lowest possible value for a given test, as is the case here, we report the p-value as being less than that value, since we've yet to observe a random alignment score at least that high. For example, here we would report something like:\n",
    "\n",
    "*The alignment of our query and reference sequence was statistically significant, as determined by comparing our actual alignment score to random variants ($p < 0.001$).*\n",
    "\n",
    "Let's now try this for some harder cases, where the query and subject sequences are not identical. First, let's generate a longer subject sequence at random. Then, we'll create a random query sequence and compare it. Since we're doing this in two random steps, we know that these sequences are not homologous. Does the resulting p-value reflect that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "---------------------------------------------------------------------\n",
       "Stats:\n",
       "    length: 250\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 53.20%\n",
       "---------------------------------------------------------------------\n",
       "0   GTAAAAAACA AGGTGGAACT CAGTCCGCGC TTAGTATAAG GGGAATCCCT ACGTGTGGTT\n",
       "60  ACCCGTTGCA CCACGAACAC CGACATCTGA GGTGAAGGTC ACTGCTCTAA TCCAGGCCAA\n",
       "120 CCGACTGGGC TTGGCTGGTT CTGCGTGCGC GTCGCAGATA CCCTGATCCC ACAAAGGCCG\n",
       "180 AGCGGCGAAA GGAAATTAGT AAGTAAACAT TATCCCATCA TATGCGCACC ACCCACATTT\n",
       "240 CACGGGCCTG"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence1 = random_sequence(skbio.DNA, 250)\n",
    "sequence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "---------------------------------------------------------------------\n",
       "Stats:\n",
       "    length: 250\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 50.00%\n",
       "---------------------------------------------------------------------\n",
       "0   AGAACTTGCA TGGGGCTACT TCCTGAAGCG GATCGTGTGC CGAACGCCCT AATTTTCCCT\n",
       "60  TATCCCTTAC GGATGGCTGA CTCTTTGCCG GATTGTACCT TACACTGTAT TCTCACGGCA\n",
       "120 CGTAGCCTTC TGAAGAGAGA AATTGGCTTT TCTACACTTT TATAGAGCGT GTGGGCGGAA\n",
       "180 CTGCGAAGGA GAGCCTCAAG GAGATAACGC TCCCTAGATT GGGCGCTGAA GTATTTTTTG\n",
       "240 GACATGGCCC"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence2 = random_sequence(skbio.DNA, 250)\n",
    "sequence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of alignment scores at least as good as the alignment score: 0.87\n"
     ]
    }
   ],
   "source": [
    "print(\"Fraction of alignment scores at least as good as the alignment score: %r\" %\n",
    "      fraction_better_or_equivalent_alignments(sequence1,sequence2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now looked at two extremes: where sequences are obviously homologous (because they were the same), and where sequences are obviously not homologous (because they were both independently randomly generated). Next, we'll explore the region between these, where this gets interesting. We'll now create a partially randomized sequence to create a pair of sequences where the homology is more obscure. We'll do this again using the Python ``random`` module, but this time we'll introduce mutations only at some positions to create a pair of sequences that are approximately ``percent_id`` identical.\n",
    "\n",
    "Let's define a function to do this, and then compute a sequence that is 95% identical to our ``sequence1``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partially_randomize_sequence(percent_id, sequence):\n",
    "    result = []\n",
    "    for c in sequence:\n",
    "        if random.random() < percent_id:\n",
    "            result.append(str(c))\n",
    "        else:\n",
    "            # choose a base at random that is not the current base\n",
    "            # i.e., simulate a substitution event\n",
    "            result.append(choice([r for r in sequence.nondegenerate_chars if r != c]))\n",
    "    return sequence.__class__(''.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence1_95 = partially_randomize_sequence(0.95, sequence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "---------------------------------------------------------------------\n",
       "Stats:\n",
       "    length: 250\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 53.20%\n",
       "---------------------------------------------------------------------\n",
       "0   GTAAAAAACA AGGTGGAACT CAGTCCGCGC TTAGTATAAG GGGAATCCCT ACGTGTGGTT\n",
       "60  ACCCGTTGCA CCACGAACAC CGACATCTGA GGTGAAGGTC ACTGCTCTAA TCCAGGCCAA\n",
       "120 CCGACTGGGC TTGGCTGGTT CTGCGTGCGC GTCGCAGATA CCCTGATCCC ACAAAGGCCG\n",
       "180 AGCGGCGAAA GGAAATTAGT AAGTAAACAT TATCCCATCA TATGCGCACC ACCCACATTT\n",
       "240 CACGGGCCTG"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "---------------------------------------------------------------------\n",
       "Stats:\n",
       "    length: 250\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 52.80%\n",
       "---------------------------------------------------------------------\n",
       "0   GTAAAAAACA AGGTGGAACT CAGTCCGCGC CCAGTATGAG GGGAATCCTT ACGTGCGGTT\n",
       "60  ACCCGTTGCA CCACGAATAC CGACATCTGA GGTGAAGGTC ACTACTCTAA TCTAGGCCAA\n",
       "120 CCGACTGGGC TTGTCTGGTT CTGCGTGCGC GTCGCAGATA CCCTGATCCC ACAAAGGACG\n",
       "180 AGCGCCGAAA GGAAATTAGT AAGTAAACAT TATCCCATCA TATGCGCACC ACCCACATCT\n",
       "240 CACGGGCCTG"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence1_95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how these sequences are almost identical, but have some differences. Let's apply our approach to determine if it would identify these sequences as being homologous based on $\\alpha = 0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of alignment scores at least as good as the alignment score: 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"Fraction of alignment scores at least as good as the alignment score: %r\" %\n",
    "      fraction_better_or_equivalent_alignments(sequence1, sequence1_95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You likely got a significant p-value there, telling you that the sequences are homologous.\n",
    "\n",
    "Now let's simulate much more distantly related sequences by introducing substitutions at many more sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence1_25 = partially_randomize_sequence(0.25, sequence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "---------------------------------------------------------------------\n",
       "Stats:\n",
       "    length: 250\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 53.20%\n",
       "---------------------------------------------------------------------\n",
       "0   GTAAAAAACA AGGTGGAACT CAGTCCGCGC TTAGTATAAG GGGAATCCCT ACGTGTGGTT\n",
       "60  ACCCGTTGCA CCACGAACAC CGACATCTGA GGTGAAGGTC ACTGCTCTAA TCCAGGCCAA\n",
       "120 CCGACTGGGC TTGGCTGGTT CTGCGTGCGC GTCGCAGATA CCCTGATCCC ACAAAGGCCG\n",
       "180 AGCGGCGAAA GGAAATTAGT AAGTAAACAT TATCCCATCA TATGCGCACC ACCCACATTT\n",
       "240 CACGGGCCTG"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNA\n",
       "---------------------------------------------------------------------\n",
       "Stats:\n",
       "    length: 250\n",
       "    has gaps: False\n",
       "    has degenerates: False\n",
       "    has definites: True\n",
       "    GC-content: 49.20%\n",
       "---------------------------------------------------------------------\n",
       "0   TTATAGCCGA TGCGTGTACT CAGGGGAAGG TCACTAGTGT GTTATTCGCA CTGCGGAGTT\n",
       "60  ACCCTTCGCG CCATCCTGAC CTAAACTCGA AATTGATGTA ACCCGTCGCT AAGGTCGAGA\n",
       "120 GTCCCTGCAG TTTAACGCTG CCACCATCGC ACTGCTTATA GTCTATTCCC CCAATGAAAG\n",
       "180 AGCTCTTAAT ACAAGACAAT ATATACGTCT AGGCAGATCT CCATCGCACA AAACAATGTC\n",
       "240 ACCCGGCCGC"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence1_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of alignment scores at least as good as the alignment score: 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"Fraction of alignment scores at least as good as the alignment score: %r\" %\n",
    "      fraction_better_or_equivalent_alignments(sequence1, sequence1_25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the limit of detection of sequence homology searches \n",
    "\n",
    "In the example above, we know that our input sequences are \"homologous\" because `sequence1_25` and `sequence1_95` are both derived from `sequence1`. Our method detected that homology for `sequence1_95`, when we simulated very closely related sequences, but not for ``sequence1_25``, when we simulated much more distantly related sequences. This gives us an idea of the limit of detection of this method, and is a real-world problem that biologists face: as sequences are more divergent from one another, detecting homology becomes increasingly difficult.\n",
    "\n",
    "Lets run a simulation to gain some more insight into the limit of detection of this method. We'll run this approach for pairs of sequences where we vary the ``percent_id`` parameter, and identify when our approach stops identifying sequence pairs as being homologous. This is important to know as a bioinformatician, because it tells us around what pairwise similarity we will no longer be able to identify homology using this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent id between query and subject</th>\n",
       "      <th>Median p-value</th>\n",
       "      <th>Mean p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.5890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.5055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.6645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.6350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.6335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.5450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.4885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Percent id between query and subject  Median p-value  Mean p-value\n",
       "0                                   0.00           0.710        0.5890\n",
       "1                                   0.05           0.520        0.5055\n",
       "2                                   0.10           0.780        0.6645\n",
       "3                                   0.15           0.705        0.6350\n",
       "4                                   0.20           0.825        0.6335\n",
       "5                                   0.25           0.550        0.5450\n",
       "6                                   0.30           0.475        0.4885\n",
       "7                                   0.35           0.205        0.3130\n",
       "8                                   0.40           0.010        0.0560\n",
       "9                                   0.45           0.010        0.0450\n",
       "10                                  0.50           0.010        0.0145\n",
       "11                                  0.55           0.010        0.0100\n",
       "12                                  0.60           0.010        0.0100\n",
       "13                                  0.65           0.010        0.0100\n",
       "14                                  0.70           0.010        0.0100\n",
       "15                                  0.75           0.010        0.0100\n",
       "16                                  0.80           0.010        0.0100\n",
       "17                                  0.85           0.010        0.0100\n",
       "18                                  0.90           0.010        0.0100\n",
       "19                                  0.95           0.010        0.0100"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's define the range of percent identities that we'll test\n",
    "percent_ids = np.arange(0.0, 1.0, 0.05)\n",
    "# Then, we'll define the number of random sequences we'll test at each percent identity\n",
    "num_trials = 20\n",
    "# Then, we'll define the sequence length that we want to work with, and num_trials random sequences\n",
    "sequence_length = 150\n",
    "random_sequences = [random_sequence(skbio.DNA, sequence_length) for i in range(num_trials)]\n",
    "\n",
    "results = []\n",
    "\n",
    "for percent_id in percent_ids:\n",
    "    # at each percent_id, we'll track the p-values for each trial (random sequence)\n",
    "    p_values = []\n",
    "    for sequence in random_sequences:\n",
    "        # partially randomize the sequence, compute its p-value, and record that p-value\n",
    "        sequence_at_percent_id = partially_randomize_sequence(percent_id, sequence)\n",
    "        p = fraction_better_or_equivalent_alignments(sequence, sequence_at_percent_id)\n",
    "        p_values.append(p)\n",
    "    results.append((percent_id, np.median(p_values), np.mean(p_values)))\n",
    "pd.DataFrame(results, columns=[\"Percent id between query and subject\",\n",
    "                               \"Median p-value\", \"Mean p-value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this simulation tell us about our limit of detection for homology (i.e., how similar must a pair of sequences be for us to reliably be able to identify homology between them)? Is this higher or lower than you expected?\n",
    "\n",
    "With respect to our simulation, I took a few shortcuts here to keep the runtime low. What are some things that could be improved to make this simulation more robust, if we weren't as concerned about runtime?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.9.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "source_map": [
   14,
   63,
   66,
   84,
   98,
   128,
   130,
   134,
   138,
   140,
   144,
   149,
   155,
   171,
   174,
   178,
   182,
   184,
   203,
   241,
   247,
   256,
   264,
   271,
   275,
   280,
   288,
   332,
   338,
   344,
   358,
   361,
   365,
   368,
   385,
   393,
   397,
   401,
   412,
   416,
   422,
   447,
   451,
   455,
   466,
   470,
   486,
   502,
   506,
   529,
   533,
   547,
   555,
   559,
   568,
   613,
   615,
   619,
   635,
   643,
   645,
   649,
   666,
   717,
   725,
   729,
   733,
   735,
   739,
   747,
   751,
   756,
   758,
   762,
   766,
   770,
   788,
   791,
   795,
   807,
   809,
   819,
   860,
   863,
   873,
   876,
   884,
   889,
   894,
   897,
   903,
   916,
   920,
   924,
   926,
   930,
   933,
   939,
   943,
   947,
   951,
   954,
   962,
   984
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}